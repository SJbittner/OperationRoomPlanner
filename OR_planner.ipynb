{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad357b2",
   "metadata": {},
   "source": [
    "# Project: Data Science - Surgical Duration\n",
    "\n",
    "Group 31\n",
    "\n",
    "Sara-Jane Bittner\n",
    "\n",
    "\n",
    "Xiao-Lan Bokma\n",
    "\n",
    "http://epydoc.sourceforge.net/epytext.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef33b77",
   "metadata": {},
   "source": [
    "# Chapter 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07477234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os #get the os filepath\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import statsmodels.api as sm  \n",
    "from scipy.stats import zscore\n",
    "\n",
    "from matplotlib.pyplot import boxplot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from numpy import mean, std, nan, float64, abs, delete, absolute, sqrt, array\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder,LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import f1_score, recall_score, average_precision_score, balanced_accuracy_score\n",
    "from sklearn import model_selection, svm, tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from operator import itemgetter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1895393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will allow our project to allways be executed in the same manor, providing us with a stable result.\n",
    "randomSeed=12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010cb1c",
   "metadata": {},
   "source": [
    "# Chapter 2 - Used functions\n",
    "The following will provide us with all the functions, that are used in our pipeline in chapter 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ce5a0",
   "metadata": {},
   "source": [
    "### 2.1 Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9382f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df_from_file(filename: str):\n",
    "    \"\"\"\n",
    "    Get the path of this file and look into the data folder that is located in the same folder as this file,\n",
    "    read the .csv file and delete the last row, as it is empty\n",
    "\n",
    "    @type filename: str\n",
    "    @param filename: The filename of the .csv spreadsheet\n",
    "    @rtype: dataframe\n",
    "    @returns: dataFrame appearing in the .csv file\n",
    "    \"\"\"\n",
    "    \n",
    "    path = os.path.join('data', filename)\n",
    "    dataFrame=pd.read_csv(path,sep=';',encoding=\"ISO-8859-1\")\n",
    "    dataFrame.drop(dataFrame.tail(1).index,inplace=True)\n",
    "    display(dataFrame)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa352",
   "metadata": {},
   "source": [
    "## 2.2 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b5bfb",
   "metadata": {},
   "source": [
    "### 2.2.1 Retype the columns\n",
    "Currently, all the dataframe columns are of type \"Object\", since the data is in string format. All the columns that are not in this shape, will need to be retyped.\n",
    "\n",
    "The columns that should be float64 are predefined already. The columns that are not recognized as float64 yet will undergo the modification. To retype the float64 columns, the string 'Onbekend' needs to be replaced with np.nan values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227c1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_nan(dataFrame, value):\n",
    "    \"\"\"\n",
    "    Replace specific a value in this dataframe to a np.nan value.\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: The dataframe with value that needs replacement.\n",
    "    @type value: string\n",
    "    @param value: The value that needs to be replaced by np.nan values\n",
    "    @rtype: dataframe\n",
    "    @returns: dataFrame with the values replaced by np.nan values.\n",
    "    \"\"\"\n",
    "    #loop through all the columns in the data and replace the value within each column.\n",
    "    for column in dataFrame:\n",
    "        dataFrame[column] = dataFrame[column].replace([value], nan)\n",
    "    return dataFrame\n",
    "\n",
    "def get_non_dtype_columns(dataFrame, dTypeColumnNames, dType):\n",
    "    \"\"\"\n",
    "    Get the columns of the dType list that are not yet of that dtype (yet): \n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: The dataframe to get the non_dTypeColumnNames columns from.\n",
    "    @type dTypeColumnNames: list\n",
    "    @param dTypeColumnNames: list of the column names that should be of the specified dType.\n",
    "    @type dType: string\n",
    "    @param dType: the specific dType that the columns should be\n",
    "    \n",
    "    @rtype: list\n",
    "    @returns: non_dTypeColumns which are not of the specific dtype (yet).\n",
    "    \"\"\"\n",
    "    non_dTypeColumnNames = dataFrame[dTypeColumnNames].select_dtypes(exclude=[dType]).columns\n",
    "    return non_dTypeColumnNames\n",
    "\n",
    "def convert_df_type(dataFrame, columns, dType):\n",
    "    \"\"\"\n",
    "    Convert the dtype of specific columns in the dataFrame to the specified dType.\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: The dataframe with columns that need to be converted to the dType.\n",
    "    @type columns: list\n",
    "    @param columns: list of the columns that should be the specified dType. \n",
    "    @type dType: string\n",
    "    @param dType: the dtype that the columns should be    \n",
    "    @rtype: dataframe\n",
    "    @returns: dataFrame with the columns 'columns' to dtype 'dType'\n",
    "    \"\"\"\n",
    "    \n",
    "    if (dType == 'float64'):\n",
    "        \n",
    "        print(columns)\n",
    "        non_dTypeColumnNames = get_non_dtype_columns(dataFrame, columns, dType)\n",
    "        \n",
    "        #change the columns that should be float64 but aren't yet.\n",
    "        # if the float value cannot be determined due to the decimal \n",
    "        # separator, commas will be resplaced by periods.\n",
    "        for columnName in non_dTypeColumnNames:\n",
    "            if dataFrame[columnName].dtype==\"int8\" or dataFrame[columnName].dtype==\"int64\":\n",
    "                dataFrame[columnName] = dataFrame[columnName].astype(float)\n",
    "            else:\n",
    "                dataFrame[columnName] = dataFrame[columnName].str.replace(',', '.').astype(float)\n",
    "            \n",
    "    #retype all the object columns to category type\n",
    "    elif (dType == 'category'):\n",
    "        dataFrame = pd.concat([\n",
    "        dataFrame.select_dtypes([], ['object']),\n",
    "        dataFrame.select_dtypes(['object']).apply(pd.Series.astype, dtype=dType)\n",
    "        ], axis=1)\n",
    "    \n",
    "    #convert the columns that are categories into intergers, \n",
    "    # based on the provided list of columns\n",
    "    elif (dType == 'int8'):\n",
    "        for columnName in columns:\n",
    "            dataFrame[columnName] = dataFrame[columnName].astype('category').cat.codes\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e43a2",
   "metadata": {},
   "source": [
    "### 2.2.2 Remove the Rows and Columns with too much NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e29e9",
   "metadata": {},
   "source": [
    "Drop columns that have more than 50% nan values. Drop the rows that will have one or more missing cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a692444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropWithTooMuchNan(dataFrame, axis):\n",
    "    \"\"\"\n",
    "    Drop the row/column that \n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: The dataframe that should have Nan rows/columns removed. \n",
    "    @param axis: integer\n",
    "    @param axis: 0 is about the row axis, 1 is the column axis.\n",
    "    @rtype: dataframe\n",
    "    @returns: dataFrame with the columns 'columns' to dtype 'dType'\n",
    "    \"\"\"\n",
    "    \n",
    "    if axis == COLUMN_AXIS:\n",
    "        allColumnNames = dataFrame.columns\n",
    "        NANColumns =[]\n",
    "        for columnName in allColumnNames:\n",
    "            if dataFrame[columnName].isnull().values.any():\n",
    "                    howManyNaN = dataFrame[columnName].isnull().sum()\n",
    "                    if howManyNaN > ((len(dataFrame[columnName])/100)*50):\n",
    "                        NANColumns += [columnName]\n",
    "                        dataFrame.drop(labels=columnName,axis=COLUMN_AXIS, inplace= True)\n",
    "        return dataFrame, NANColumns\n",
    "    \n",
    "    elif axis == ROW_AXIS:\n",
    "        # drop the rows that have missing values.\n",
    "        dataFrame.dropna(thresh= len(dataFrame.columns), inplace = True)\n",
    "        dataFrame.isnull().values.any()\n",
    "        dataFrame = dataFrame.reset_index(drop=True)\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526e6ce",
   "metadata": {},
   "source": [
    "### 2.2.3 Creation of new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c67a32",
   "metadata": {},
   "source": [
    "Creating the Overtime column based on the current planned Duration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0852d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOvertimeColumn(dataFrame):\n",
    "    \"\"\"\n",
    "    Create the Overtime column by substracting ActualDurationTime from the PlannedDurationTime\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: The dataframe that containt the two columns that should become a new column.\n",
    "    @rtype: dataframe\n",
    "    @returns: dataFrame with the extra \"Overtime\" column.\n",
    "    \"\"\"\n",
    "    dataFrame['Overtime'] = dataFrame['ActualDurationTime'] - dataFrame['PlannedDurationTime']\n",
    "    RANGE_COLUMN_NAMES.append('Overtime')\n",
    "    ORDINAL_COLUMN_NAMES.append('Overtime')\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24871ba7",
   "metadata": {},
   "source": [
    "Create the OperationType Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce0a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTypeEncoder:\n",
    "    relevant_op_types=[\"other\"] #list of the n% most common operations\n",
    "    relevant_op_types_Names=[\"OPType_other\"]\n",
    "    n=99\n",
    "    def __init__(self, n):\n",
    "        self.n=n\n",
    "    \n",
    "    def splitOPTypeText(self,text):\n",
    "        thisPatientsOPs=str(text).lower().strip().split(\" + \")\n",
    "        return [i.strip() for i in thisPatientsOPs]\n",
    "        \n",
    "    def fit(self,dataframe, columnname):\n",
    "        \"\"\"creates a list of relevant operationtypes.\"\"\"\n",
    "        \n",
    "        #get a list of all operations, that have ever been done\n",
    "        completeOPList=[]\n",
    "        for patient in dataframe[columnname]:\n",
    "            #print(patient)\n",
    "            thisPatientsOPs=self.splitOPTypeText(patient)\n",
    "            completeOPList+=thisPatientsOPs\n",
    "        \n",
    "        #find out how often they have been done\n",
    "        to_n_uses=FreqDist(completeOPList)\n",
    "        dictionary_items = to_n_uses.items()\n",
    "        to_n_uses = sorted(dictionary_items, key=itemgetter(1), reverse=True )\n",
    "        \n",
    "        #get the operations, that together are used in n% percent of the cases\n",
    "        threshold=(self.n*len(dataframe[columnname]))/100 # Define how many cases should be covered by the amount of operations.\n",
    "        i=0\n",
    "        for ot in to_n_uses:\n",
    "            #print(ot)\n",
    "            if ot[0] == \"nan\":\n",
    "                pass\n",
    "            else:\n",
    "                i+=ot[1]\n",
    "                self.relevant_op_types.append((ot[0]))\n",
    "                if i>=threshold:\n",
    "                    break\n",
    "        print(\"The relevant op types, that cover at least\",str(self.n)+\"% of all operations, are:\", self.relevant_op_types)\n",
    "        self.relevant_op_types_Names=[\"OPType_\"+i for i in self.relevant_op_types]\n",
    "        \n",
    "        \n",
    "    def transform(self,dataframe, columnname):\n",
    "        \n",
    "        allPatientsOHE=[]\n",
    "        \n",
    "        #add J if this operation was done for this patient, \n",
    "        #add N if this operation was not done for this patient\n",
    "        #add nan, if the operation was unknown\n",
    "        for patient in dataframe[columnname]:\n",
    "            #print(patient)\n",
    "            thisPatientsOPs=self.splitOPTypeText(patient)\n",
    "            \n",
    "            #add a column for each relevant operationtype\n",
    "            thisPatientsOHE=[\"N\"]*len(self.relevant_op_types)\n",
    "            for op in thisPatientsOPs:\n",
    "                if op ==\"nan\":\n",
    "                    thisPatientsOHE=[nan]*len(self.relevant_op_types)\n",
    "                elif op in self.relevant_op_types:\n",
    "                    i=self.relevant_op_types.index(op)\n",
    "                    thisPatientsOHE[i]=\"J\"\n",
    "                elif not(op in self.relevant_op_types):\n",
    "                    thisPatientsOHE[0]=\"J\"\n",
    "            allPatientsOHE.append(thisPatientsOHE)\n",
    "         \n",
    "        #turn the results into a dataframe\n",
    "        allPatientsOHE_DF=pd.DataFrame(allPatientsOHE, columns= self.relevant_op_types_Names)\n",
    "        \n",
    "        #remove old column from df\n",
    "        dataframe = dataframe.drop(labels = columnname, axis=COLUMN_AXIS)\n",
    "        \n",
    "        #add new columns to df\n",
    "        dataframe = pd.merge(dataframe, allPatientsOHE_DF, left_index=True, right_index=True)\n",
    "        \n",
    "        #edit\n",
    "        CATEGORICAL_COLUMN_NAMES.remove(columnname)\n",
    "        SURGERY_FEATURES.remove(columnname)\n",
    "        for column in self.relevant_op_types_Names:\n",
    "            BINARY_COLUMN_NAMES.append(column)\n",
    "            SURGERY_FEATURES.append(column)\n",
    "            \n",
    "        \n",
    "        return dataframe\n",
    "        \n",
    "    def fit_transform(self,dataframe, columnname):\n",
    "        self.fit(dataframe, columnname)\n",
    "        return self.transform(dataframe, columnname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b8b5c",
   "metadata": {},
   "source": [
    "### 2.3.4 Outliers\n",
    "\n",
    "#### Categorical Outlier Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9c8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupOutliers(dataFrame, columnName, treshhold):\n",
    "    '''\n",
    "    Group the outlier categories into one group, called 'other'.\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: the dataframe with the categorical column \n",
    "    @type columnNames: list\n",
    "    @param columnNames: list of the column names that need to be outlier cut\n",
    "    @type treshold: float\n",
    "    @param treshold: percentage that needs to be cut off.\n",
    "    \n",
    "    @rtype dataFrame: dataframe\n",
    "    @returns dataFram: dataframe with the cut off outliers based on the treshold.\n",
    "    '''\n",
    "    treshAmount = (len(dataFrame)//100)*treshhold\n",
    "    threshCounter = 0\n",
    "    countValues = dataFrame[columnName].value_counts()\n",
    "    uniqueValues = dataFrame[columnName].unique()\n",
    "    \n",
    "    for uniqueValue in reversed(uniqueValues):\n",
    "        if (threshCounter + countValues[uniqueValue]) <= treshAmount:\n",
    "            threshCounter += countValues[uniqueValue]\n",
    "            dataFrame[columnName].replace([uniqueValue],'other', inplace=True)\n",
    "\n",
    "    dataFrame[columnName] = dataFrame[columnName].cat.remove_unused_categories()\n",
    "    return dataFrame\n",
    "    \n",
    "def categorical_outlier_cutting(dataFrame, columnNames, treshold):\n",
    "    '''\n",
    "    Group the outlier categories into one group, called 'other'.\n",
    "    These outliers will be defined according to the treshold.\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: the dataframe with the categorical column \n",
    "    @type columnNames: list\n",
    "    @param columnNames: list of the column names that need to be outlier cut\n",
    "    @type treshold: float\n",
    "    @param treshold: percentage that needs to be cut off.\n",
    "    \n",
    "    @rtype dataFrame: dataframe\n",
    "    @returns dataFram: dataframe with the cut off outliers based on the treshold.\n",
    "    '''\n",
    "    for column in columnNames:\n",
    "#         print (\"BEFORE: \", dataFrame[column].value_counts())\n",
    "        dataFrame=groupOutliers(dataFrame, column, treshold)\n",
    "#         print (\"AFTER: \", dataFrame[column].value_counts())\n",
    "#     print(dataFrame['Surgeon'].value_counts())\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79973241",
   "metadata": {},
   "source": [
    "#### Numerical Outlier Cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03eab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_outlier_cutting(dataFrame, numericalColumnNames):\n",
    "    '''\n",
    "    Define the numerical outliers, based on the z-scores. Based on the range 2, the outliers will be cut.    \n",
    "    \n",
    "    @type dataFrame: dataFrame\n",
    "    @param dataFrame: the datafram that contains the columns that need to have the values outliercut.\n",
    "    @type numericalColumnNames: list\n",
    "    @param numericalColumnNames: list of the columnNames with numerical data.\n",
    "    \n",
    "    @rtype dataFrame: dataframe\n",
    "    @returns dataFrame: dataframe with the numerical outliers cut.\n",
    "    '''\n",
    "    \n",
    "#     minValue = dataFrame[columnName].min()\n",
    "#     maxValue = dataFrame[columnName].max()\n",
    "\n",
    "#     print(minValue) \n",
    "#     print(maxValue) \n",
    "\n",
    "    numericalData = dataFrame[numericalColumnNames]\n",
    "\n",
    "    z_scores = zscore(numericalData)\n",
    "    abs_z_scores = abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 2).all(axis=1)\n",
    "    dataFrame = dataFrame[filtered_entries]\n",
    "    dataFrame = dataFrame.reset_index(drop=True)\n",
    "\n",
    "#     minValue = dataFrame['PlannedDurationTime'].min()\n",
    "#     maxValue = dataFrame['PlannedDurationTime'].max()\n",
    "\n",
    "#     print(minValue) #minutes\n",
    "#     print(maxValue) #minutes\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae898c1",
   "metadata": {},
   "source": [
    "### 2.2.5 Creating categorical data from numerical data ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2350e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<ipython-input-10-dbf2687cf347>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if columnName is not 'PlannedDurationTime' and columnName is not 'ActualDurationTime':\n",
      "<ipython-input-10-dbf2687cf347>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if columnName is not 'PlannedDurationTime' and columnName is not 'ActualDurationTime':\n"
     ]
    }
   ],
   "source": [
    "def get_bins (columnData, columnName):\n",
    "    minValue = columnData.min()\n",
    "    maxValue = columnData.max()\n",
    "    \n",
    "#     print(minValue) #minutes\n",
    "#     print(maxValue) #minutes\n",
    "    \n",
    "    if columnName == \"BMI\":    \n",
    "        bins = [(minValue-1),18.5,24.9,29.9,maxValue]\n",
    "        binNames = ['underweight', 'normal', 'overweight', 'obese']\n",
    "    elif columnName == \"Age\":\n",
    "        bins = [int(minValue-1), 57, 66,76, int(maxValue)]\n",
    "        binNames = [ (str(x+1)+'-'+str(y)) for x,y in zip(bins[0::1], bins[1::1]) ]\n",
    "    elif columnName == \"Overtime\":\n",
    "        bins = [(minValue-1),(-70),(-25),25,70, 120,(maxValue)]\n",
    "        binNames = ['Ahead_Of_Time_Extreme','Ahead_Of_Time_Medium', 'In_Time','Overtime_Small','Overtime_Medium', 'Overtime_Extreme']\n",
    "    elif columnName == \"ActualDurationTime\":\n",
    "        bins = [int(minValue-1), 180, 240, 280, 345,int(maxValue)]\n",
    "        binNames = [ (str(x+1)+'-'+str(y)) for x,y in zip(bins[0::1], bins[1::1]) ]\n",
    "    elif columnName == \"PlannedDurationTime\":\n",
    "        bins = [int(minValue-1), 180, 240, 280, int(maxValue)]\n",
    "        binNames = [ (str(x+1)+'-'+str(y)) for x,y in zip(bins[0::1], bins[1::1]) ]    \n",
    "    return bins, binNames\n",
    "\n",
    "def convert_categorical_range(dataFrame, columnName):\n",
    "\n",
    "    bins, binNames = get_bins(dataFrame[columnName], columnName)\n",
    "    \n",
    "    dataFrame[columnName + 'Range'] = pd.cut(dataFrame[columnName], bins, labels=binNames)\n",
    "    #TODO Check <>:31: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
    "    if columnName is not 'PlannedDurationTime' and columnName is not 'ActualDurationTime': \n",
    "        dataFrame.drop(labels = columnName, axis=COLUMN_AXIS, inplace = True)\n",
    "    \n",
    "#     replace_columnName_in_lists(columnName, columnName+'Range')\n",
    "    \n",
    "    print(dataFrame[columnName + 'Range'].value_counts())\n",
    "    print (bins)\n",
    "    print(len(bins))\n",
    "    print(binNames)\n",
    "    print(len(binNames))\n",
    "\n",
    "    # add BMIRange to patientFeatures-List\n",
    "#     PATIENT_FEATURES += (columnName + 'Range')\n",
    "\n",
    "    return dataFrame, binNames\n",
    "\n",
    "def to_categorical_range(dataFrame):\n",
    "    column2binNames={}\n",
    "    for columnName in RANGE_COLUMN_NAMES:\n",
    "        dataFrame, binNames = convert_categorical_range(dataFrame, columnName)\n",
    "#     dataFrame = convert_categorical_range(dataFrame, 'BMI')\n",
    "#     dataFrame = convert_categorical_range(dataFrame, 'Age')\n",
    "# #     dataFrame = convert_categorical_range(dataFrame, 'Overtime')\n",
    "#     dataFrame = convert_categorical_range(dataFrame, 'ActualDurationTime')\n",
    "#     dataFrame = convert_categorical_range(dataFrame, 'PlannedDurationTime')\n",
    "        column2binNames[columnName+\"Range\"]=binNames\n",
    "    return dataFrame, column2binNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564ac9c",
   "metadata": {},
   "source": [
    "### 2.2.6 Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f7776",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e1f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(dataFrame, columns):\n",
    "    #print(ORDINAL_COLUMN_NAMES)\n",
    "    \n",
    "    columnNameToLE={}\n",
    "\n",
    "        \n",
    "    for columnName in columns:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(dataFrame[columnName])\n",
    "        dataFrame[columnName] = le.transform(dataFrame[columnName])\n",
    "        columnNameToLE[columnName]=le\n",
    "        \n",
    "    print(dataFrame['ActualDurationTimeRange'].value_counts()) #todo\n",
    "    return dataFrame, columnNameToLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85faacc5",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff71f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntTransfer(dataFrame, columnName):\n",
    "    '''\n",
    "    Make string type floats into int.\n",
    "    When the decimal separator is ',' replace it with a '.' first.\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame: \n",
    "    @type columnName: string\n",
    "    @param columnName:\n",
    "    \n",
    "    @rtype dataFrame: dataframe\n",
    "    @returns dataFrame:\n",
    "    \n",
    "    '''\n",
    "    for i in range(0,len(dataFrame[columnName])):\n",
    "        try:\n",
    "            dataFrame[columnName][i]= int(float(dataFrame[columnName][i].replace(\",\",\".\")))\n",
    "        except ValueError:\n",
    "            dataFrame[columnName][i]= dataFrame[columnName][i]\n",
    "            \n",
    "    return dataFrame\n",
    "\n",
    " \n",
    "def one_hot_encoding(columnNames, dataFrame):\n",
    "    '''\n",
    "    Onehot-encodes the columns of the dataFrame, which are listed in columnNames\n",
    "    \n",
    "    @type dataFrame: dataframe\n",
    "    @param dataFrame:\n",
    "    \n",
    "    @rtype dataFrame:\n",
    "    @returns list:\n",
    "    @rtype dict: allows for reconecting the name of the column to the corresponding encoder.\n",
    "    '''   \n",
    "    \n",
    "    \n",
    "    columnNameToOHE={}\n",
    "    \n",
    "    #for each column, which needs to be OHEd create an OH-Encoder and the corresponding Encoding. Insert it in the Dataframe\n",
    "    for columnName in columnNames:\n",
    "        print(columnName)\n",
    "        dataFrame = IntTransfer(dataFrame,columnName)\n",
    "        hotCodedArray=array(dataFrame[columnName][:]).reshape(-1, 1)\n",
    "        \n",
    "        #create an OH-Encoder and the corresponding Encoding\n",
    "        \n",
    "        #enc= LabelBinarizer()\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        hotCodedArray=enc.fit_transform(hotCodedArray).toarray()\n",
    "        columnNameToOHE[columnName]=enc\n",
    "        \n",
    "        #Find out columnames\n",
    "        hotCodedcolumns=[]\n",
    "        for category in list(enc.categories_[0]):\n",
    "            hotCodedcolumns+=[columnName+\"_\"+str(category)]\n",
    "        \n",
    "        \n",
    "        #create a new df, using the hot coded columns as Column Names\n",
    "        hotCoded = pd.DataFrame(hotCodedArray, columns = hotCodedcolumns)\n",
    "\n",
    "        #remove old data column and add new dataframe\n",
    "        dataFrame.drop(labels=columnName,axis=COLUMN_AXIS, inplace= True)\n",
    "        dataFrame = pd.merge(dataFrame, hotCoded, left_index=True, right_index=True)\n",
    "        \n",
    "    return dataFrame, columnNameToOHE.keys(), columnNameToOHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dad1c",
   "metadata": {},
   "source": [
    "#### Calculate the VIF for One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3583fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateVIF(df, featuresToTest):\n",
    "    \n",
    "    #Filters the whole dataset for the feature set of one OneHotEncoded-Column\n",
    "    independentVariables = df.filter(featuresToTest)\n",
    "    \n",
    "    #print(independentVariables.head())\n",
    "    X = independentVariables\n",
    "  \n",
    "    # VIF dataframe\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "    # calculating VIF for each feature\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    return vif_data\n",
    "                                                 \n",
    "def checkForMultiCol(df, featuresToTest):\n",
    "    multicols =[]\n",
    "    #calculate the Variance Inflation Factor and gives a table with all VIF with the features back\n",
    "    vifData = calculateVIF(df, featuresToTest)\n",
    "    #Goes through the table and checks for multicollinearity\n",
    "    for i in range(0,len(vifData)-1):\n",
    "            # >= 5 because from 5 multicollinearity is there\n",
    "            if vifData['VIF'][i] >= 5:\n",
    "                print(vifData['VIF'][i])\n",
    "                #saves features that are multicollinearity in list\n",
    "                multicols +=[vifData['feature'][i]]\n",
    "    #print(multicols)\n",
    "    return multicols\n",
    "\n",
    "def multi_col_test(dataFrame):\n",
    "    #Test if there is Multicollinearity in the OneHotEncoding\n",
    "    multicols =[]\n",
    "    for i in range(0,len(CATEGORICAL_COLUMN_NAMES)):\n",
    "        #print(list(hotCodedNames[i]))\n",
    "        multicols +=checkForMultiCol(dataFrame, list(CATEGORICAL_COLUMN_NAMES[i]))\n",
    "    if (len(multicols)==0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d3552",
   "metadata": {},
   "source": [
    "## 2.2.7 Normalization\n",
    "Normalize:\n",
    "- Numerical.\n",
    "- label encoded data.\n",
    "\n",
    "Don't normalize:\n",
    "- Binary Data .\n",
    "- One Hot Encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be97fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataFrame):\n",
    "    normalizationData = dataFrame[NORMALIZATION_COLUMN_NAMES]\n",
    "\n",
    "    x = normalizationData.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    normalizedDf = pd.DataFrame(x_scaled, columns=NORMALIZATION_COLUMN_NAMES)\n",
    "    #print(sD.columns)\n",
    "    dataFrame.drop(labels = NORMALIZATION_COLUMN_NAMES, inplace=True, axis = 1)\n",
    "    #print(sD.columns)\n",
    "\n",
    "    dataFrame = pd.merge(dataFrame, normalizedDf, left_index=True, right_index=True)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2a72c",
   "metadata": {},
   "source": [
    "## 2.3 -Feature Selection\n",
    "### 2.3.1 New Feature Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377df500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_data(dataFrame, featureColumnNames):    \n",
    "    featureData = dataFrame.drop(labels = OUTCOME_COLUMN_NAMES, axis = COLUMN_AXIS)\n",
    "    \n",
    "    #filter out the columnNames from a specific pool of columnNames: \n",
    "    # - surgery features or patient features\n",
    "    featureData = featureData.filter(featureColumnNames)\n",
    "    \n",
    "    # print(featureData)\n",
    "    return featureData\n",
    "    \n",
    "def backward_elimination(X, y):\n",
    "\n",
    "    #Adding constant column of ones, mandatory for sm.OLS model\n",
    "    X_1 = sm.add_constant(X)\n",
    "    \n",
    "    #Fitting sm.OLS model\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    #model.pvalues\n",
    "\n",
    "    #Extract columnsNames\n",
    "    columnNames = list(X.columns)\n",
    "    #print(len(columnNames)) #62\n",
    "    SIGNIFICANCE = 0.05\n",
    "\n",
    "    #Set the pmax variable to 1. Will be replaced in while loop.\n",
    "    pmax = 1\n",
    "\n",
    "    #while the length of the columnNames is not empty (yet).\n",
    "    #wrapper methods:\n",
    "    #     Backwards elimination = single features only.\n",
    "    #     Filter method is = combination of features.\n",
    "    while (len(columnNames)>0):\n",
    "\n",
    "        # initialize an empty list for all the pValues.\n",
    "        p= []\n",
    "\n",
    "        # make the statistical model and fit it to the data.\n",
    "        X_1 = X[columnNames]\n",
    "        X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
    "        model = sm.OLS(y,X_1).fit()\n",
    "\n",
    "        new_arr = delete(model.pvalues.values, (len(model.pvalues.values)-1))\n",
    "\n",
    "        #make a dataframe with the columnNames and their corresponding P values.\n",
    "        p = pd.Series(new_arr,index = columnNames)\n",
    "\n",
    "        # extract the maximum P value of the column.\n",
    "        pmax = max(p)\n",
    "        feature_with_p_max = p.idxmax()\n",
    "\n",
    "        # compare the p value with the significance value.\n",
    "        # if the pmax is bigger than the significance value, the specific \n",
    "        # feature is insignificant and removes it from the list.\n",
    "        if(pmax>SIGNIFICANCE):\n",
    "            #print(feature_with_p_max)\n",
    "            columnNames.remove(feature_with_p_max)\n",
    "\n",
    "        # if there is no maximum p-value that is insignificant anymore, the while loop will break.\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    selectedFeatures = columnNames\n",
    "\n",
    "    #print(len(selectedFeatures))\n",
    "    #print(selectedFeatures)\n",
    "    \n",
    "    featuresDataSelected = X.filter(selectedFeatures)\n",
    "    #print(featuresDataSelected.info())\n",
    "    \n",
    "    selectedFeaturesColumnNames = featuresDataSelected.columns\n",
    "    #print(selectedFeaturesColumnNames)\n",
    "    \n",
    "    return featuresDataSelected, list(selectedFeaturesColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40dc7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_names_string(yColumn):\n",
    "\n",
    "    #initialize which column will be the y in the model.\n",
    "    #print(yColumn.unique())\n",
    "\n",
    "    #initialize the list for the targetnames.\n",
    "    targetNames = list(yColumn.unique())\n",
    "    #print(targetNames)\n",
    "\n",
    "    #initalize for the classification report\n",
    "    targetNamesString = [str(i) for i in targetNames]\n",
    "#     print(outcomeData.columns)\n",
    "\n",
    "    #print(yColumn.unique())\n",
    "    \n",
    "    return targetNamesString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7420d",
   "metadata": {},
   "source": [
    "### 2.3.2 Inverted Indexes Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28173715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index_to_value_column(temp_dict, column, value, index):\n",
    "            \n",
    "    if value not in temp_dict[column]: temp_dict[column][value] = []\n",
    "    \n",
    "    #add the index to the specific value of that column\n",
    "    temp_dict[column][value].extend(index)\n",
    "    return temp_dict\n",
    "\n",
    "def create_ii(X_array):\n",
    "    ii = None\n",
    "\n",
    "    #create inverted index\n",
    "    for index, vector in enumerate(X_array):\n",
    "        #build inverted index and make slots for the columns\n",
    "        if ii == None: ii = [{} for _ in vector]\n",
    "\n",
    "        #for every column in this rowVector\n",
    "        for column, value in enumerate(vector):\n",
    "            ii = add_index_to_value_column(ii, column, value, [index])\n",
    "    return ii\n",
    "\n",
    "def retrieve_vectors_ii(ii, query_vector):\n",
    "    scores = {}\n",
    "    \n",
    "    #for every column in the query vector\n",
    "    for qcolumn, qvalue in enumerate(query_vector): \n",
    "        \n",
    "        #count the map indexes(documents) containing this word and how many times document appears in ii.\n",
    "        if qvalue in ii[qcolumn]:\n",
    "            \n",
    "            #get the indices that have this column value\n",
    "            ret_indices = ii[qcolumn][qvalue]\n",
    "            \n",
    "            #add the indices to the score for each appearing indices.\n",
    "            #it counts for every column the reoccuring indices.\n",
    "            for i in ret_indices:\n",
    "                if i not in scores:\n",
    "                    scores[i] = 1\n",
    "                else: \n",
    "                    scores[i] += 1\n",
    "                    \n",
    "    # find the highest score: the score for the indices that\n",
    "    # are most similar. \n",
    "    # Retrieve the indices with this score: most similar to the query vector.\n",
    "    max_val = max(scores.values())\n",
    "    max_keys = [key for key in scores if scores[key] == max_val]\n",
    "    return max_keys\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "def retrieve_y_values(indices, y_array):\n",
    "    count = 0\n",
    "    \n",
    "    #make a list with the length of the amount of retrieved indices\n",
    "    y_value = [None]*len(indices)\n",
    "    \n",
    "    #count for each appearing index, how many times it appears in total.\n",
    "    for index in indices:\n",
    "        y_value[count] = y_array[index]\n",
    "        count += 1\n",
    "        \n",
    "    return y_value\n",
    "\n",
    "\n",
    "def predict_y_ii (ii, X_array, y_array):\n",
    "    pred = [None]*len(X_array)\n",
    "    \n",
    "    for i, qvector in enumerate(X_array):\n",
    "        \n",
    "        #retrieve the similar indices for this query vector\n",
    "        most_sim_indices = retrieve_vectors_ii(ii, qvector) \n",
    "        \n",
    "        #retrieve the according y values for the most appearing indices.\n",
    "        y_values = retrieve_y_values(most_sim_indices, y_array)\n",
    "        \n",
    "        prediction = most_frequent(y_values)\n",
    "        pred[i] = prediction\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c20cd",
   "metadata": {},
   "source": [
    "## 2.4 Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243bd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportModelPerformance(model, cv, X, y):\n",
    "    # evaluate model\n",
    "    accuracy_scores = model_selection.cross_val_score(model, X, y, scoring='accuracy', cv=cv,n_jobs=-1)\n",
    "    recall_scores = model_selection.cross_val_score(model, X, y, scoring='recall', cv=cv,n_jobs=-1)\n",
    "    avPrecicion_scores = model_selection.cross_val_score(model, X, y, scoring='average_precision', cv=cv,n_jobs=-1)\n",
    "    f1_scores = model_selection.cross_val_score(model, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)\n",
    "    f1_scores_macro = model_selection.cross_val_score(model, X, y, scoring='f1_weighted', cv=cv,n_jobs=-1)\n",
    "    mae = model_selection.cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    rmse = model_selection.cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "   \n",
    "    # report performance\n",
    "    print('Accuracy score \\t %0.3f with a standard deviation of %0.3f' % (accuracy_scores.mean(), accuracy_scores.std()))\n",
    "    print(\"F1 macro score \\t %0.3f with a standard deviation of %0.3f\" % (f1_scores_macro.mean(), f1_scores_macro.std()))\n",
    "    print(\"F1 weighted sc \\t %0.3f with a standard deviation of %0.3f\" % (f1_scores.mean(), f1_scores.std()))\n",
    "    \n",
    "    # NaN because y is an object\n",
    "#     print(\"Recall \\t{}\\t with a standard deviation of {}\".format(recall_scores.mean(), recall_scores.std()))\n",
    "#     print(\"Average pre \\t{}\\t with a standard deviation of {}\".format(avPrecicion_scores.mean(), avPrecicion_scores.std()))\n",
    "\n",
    "    # view mean absolute error:\n",
    "    # the average absolute error between the model prediction and the actual observed data\n",
    "    # In general, the lower the MAE, the more closely a model is able to predict the actual observations.    \n",
    "    print ('MAE error \\t %0.3f' % (mean(absolute(mae))))\n",
    "    print ('RMSE error \\t %0.3f' % (mean(absolute(rmse))))\n",
    "    print ()\n",
    "    \n",
    "\n",
    "    \n",
    "def reportPerformance(groundTruth, predictions, report_mode):\n",
    "    \"\"\"#reports the quality of the prediction.\n",
    "    #the value that determines the best classifier, depends on the report_mode\n",
    "    \"continuos\" --> RMSE\n",
    "    \"categorical\" --> Accuracy\n",
    "    \n",
    "    if report_mode == \"continuos\" the accuracy/F1-Scores is not computed, to avoid problems with regression based classifiers\n",
    "    \"\"\"\n",
    "    if report_mode != \"continuos\":\n",
    "        #printing the classification report of the performance\n",
    "        accuracy=accuracy_score(groundTruth, predictions)\n",
    "        f1macro=f1_score(groundTruth, predictions, average='macro')\n",
    "        f1weighted=f1_score(groundTruth, predictions, average='weighted')\n",
    "        print ('Accuracy score \\t %0.3f'%(accuracy))\n",
    "        print ('F1 Macro score \\t %0.3f'%(f1macro))\n",
    "        print ('F1 Weighted sc \\t %0.3f'%(f1weighted))\n",
    "    \n",
    "    MAE=mean_absolute_error(groundTruth, predictions)\n",
    "    RMSE=sqrt(mean_squared_error(groundTruth, predictions))\n",
    "    \n",
    "    #     print ('Recall \\t{}'.format(recall_score(groundTruth, predictions, average = 'weighted')))\n",
    "    #     print ('Average prec \\t{}'.format(average_precision_score(groundTruth, predictions)))\n",
    "    print ('MAE error \\t %0.3f'%(MAE))\n",
    "    print ('RMSE error \\t %0.3f'%(RMSE))\n",
    "    print ()\n",
    "    if report_mode == \"continuos\":\n",
    "        return -RMSE\n",
    "    else:\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746907bc",
   "metadata": {},
   "source": [
    "# Chapter 3 - The Pipeline\n",
    "\n",
    "## 3.0 Preparation\n",
    "\n",
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b48b3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'surgical_case_durations.csv'      # The Filename of the csv file, that we are using.\n",
    "COLUMN_AXIS = 1                               #\n",
    "ROW_AXIS = 0                                  #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6b259",
   "metadata": {},
   "source": [
    "Here you can choose what you want to predict. Choose between:\n",
    "\n",
    "'ActualDurationTime' \n",
    "\n",
    "'ActualDurationTimeRange' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e0ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, Type in your choice:ActualDurationTime\n"
     ]
    }
   ],
   "source": [
    "# PREDICTED_COLUMN='ActualDurationTime'\n",
    "PREDICTED_COLUMN=input(\"Please, Type in your choice 'ActualDurationTime' or 'ActualDurationTimeRange': \")    # The Column that we want to predict using this pipeline. Can be: ActualDurationTimeRange or ActualDurationTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546b002",
   "metadata": {},
   "source": [
    "#### Lists and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73ffac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary for the column renamings\n",
    "TO_ENGLISH_COLUMNS={\"Geplande operatieduur\": \"PlannedDurationTime\",\n",
    "                    \"Operatieduur\": \"ActualDurationTime\",\n",
    "                    \"Operatietype\":\"OperationType\",\n",
    "                    \"Chirurg\":\"Surgeon\",\n",
    "                    \"Anesthesioloog\":\"Anesthesiologist\",\n",
    "                    \"Benadering\":\"Approach\",\n",
    "                    \"OK\":\"OperationRoom\",\n",
    "                    \"Casustype\":\"Urgency\",\n",
    "                    \"Dagdeel\":\"PartOfDay\",\n",
    "                    \"Leeftijd\":\"Age\",\n",
    "                    \"AF\":\"AtrialFibrillation\",\n",
    "                    \"HLM\":\"CardiopulmonaryBypassUse\",\n",
    "                    \"Geslacht\":\"Sex\",\n",
    "                    \"Aantal anastomosen\":\"AmountOfBypasses\",\n",
    "                    \"Chronische longziekte\":\"P_ChronicLungDisease\",\n",
    "                    \"Extracardiale vaatpathie\":\"P_extracardialArteriopathy\",\n",
    "                    \"Actieve endocarditis\": \"P_activeEndocarditis\",\n",
    "                    \"Hypertensie\":\"P_Hypertension\",\n",
    "                    \"Pulmonale hypertensie\":\"P_PulmonaleHypertension\",\n",
    "                    \"Slechte mobiliteit\":\"P_PoorMobility\",\n",
    "                    \"Hypercholesterolemie\":\"P_Hypercholesterolemia\",\n",
    "                    \"Perifeer vaatlijden\":\"P_PeripherialVascularDisease\",\n",
    "                    \"Linker ventrikel functie\":\"LeftVentricleFunction\",\n",
    "                    \"Nierfunctie\":\"RenalFunction\",\n",
    "                    \"DM\":\"P_Diabetis\",\n",
    "                    \"Eerdere hartchirurgie\":\"PreviousHeartSurgery\",\n",
    "                    \"Kritische preoperatieve status\":\"CriticalPre-OP\",\n",
    "                    \"Myocard infact <90 dagen\":\"MycordialInfarctionPreSurgery\",\n",
    "                    \"Aorta chirurgie\":\"AorticSurgery\",\n",
    "                    \"Ziekenhuis ligduur\":\"HospitalDays\",\n",
    "                    \"IC ligduur\":\"ICUDays\"\n",
    "                   }\n",
    "\n",
    "#All features, that are related to the patient\n",
    "PATIENT_FEATURES= ['Urgency', 'Sex',\n",
    "       'AtrialFibrillation', 'P_ChronicLungDisease',\n",
    "       'P_extracardialArteriopathy', 'PreviousHeartSurgery',\n",
    "       'P_activeEndocarditis', 'CriticalPre-OP',\n",
    "       'MycordialInfarctionPreSurgery', 'AorticSurgery',\n",
    "       'P_PulmonaleHypertension', 'LeftVentricleFunction', 'Euroscore1',\n",
    "       'Euroscore2', 'RenalFunction', 'P_PoorMobility', 'P_Diabetis',\n",
    "       'P_Hypercholesterolemia', 'P_Hypertension',\n",
    "       'P_PeripherialVascularDisease', 'CCS', 'NYHA', 'AmountOfBypasses',\n",
    "       'CardiopulmonaryBypassUse']\n",
    "\n",
    "#Features that are related to the surgery\n",
    "SURGERY_FEATURES =[ 'Surgeon', 'Anesthesiologist', 'Approach',\n",
    "       'OperationRoom','PartOfDay', 'OperationType']\n",
    "#________________________________________\n",
    "\n",
    "RANGE_COLUMN_NAMES = ['Age', 'BMI', 'ActualDurationTime',\n",
    "                         'PlannedDurationTime'] #and overtime\n",
    "\n",
    "ORDINAL_COLUMN_NAMES = RANGE_COLUMN_NAMES + ['CCS', 'NYHA', 'Urgency',  \n",
    "                         'LeftVentricleFunction', 'RenalFunction',\n",
    "                         'P_PulmonaleHypertension']\n",
    "\n",
    "NON_ORDINAL_COLUMN_NAMES = ['AmountOfBypasses', 'Euroscore1',\n",
    "                            'Euroscore2', 'HospitalDays', 'ICUDays']\n",
    "\n",
    "NUMERICAL_COLUMN_NAMES = RANGE_COLUMN_NAMES + NON_ORDINAL_COLUMN_NAMES\n",
    "\n",
    "CATEGORICAL_COLUMN_NAMES = ['Surgeon', 'OperationRoom', 'OperationType',\n",
    "                            'Anesthesiologist', 'Approach', 'PartOfDay']\n",
    "#________________________________________\n",
    "\n",
    "BINARY_COLUMN_NAMES = ['Sex', 'AtrialFibrillation', 'P_ChronicLungDisease',\n",
    "                        'P_extracardialArteriopathy', 'PreviousHeartSurgery', \n",
    "                        'P_activeEndocarditis', 'CriticalPre-OP',\n",
    "                        'MycordialInfarctionPreSurgery', 'AorticSurgery',\n",
    "                        'P_PoorMobility', 'P_Diabetis', 'P_Hypercholesterolemia',\n",
    "                        'P_Hypertension', 'P_PeripherialVascularDisease', \n",
    "                        'CardiopulmonaryBypassUse']\n",
    "\n",
    "NORMALIZATION_COLUMN_NAMES = ['CCS', 'NYHA', 'Urgency', 'BMIRange',\n",
    "                       'LeftVentricleFunction', 'RenalFunction',\n",
    "                       'P_PulmonaleHypertension', 'AgeRange', 'Euroscore1', \n",
    "                       'Euroscore2']\n",
    "\n",
    "OUTCOME_COLUMN_NAMES = ['HospitalDays', 'ICUDays', 'PlannedDurationTime', \n",
    "                        'PlannedDurationTimeRange', 'OvertimeRange',\n",
    "                        'ActualDurationTimeRange','ActualDurationTime']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4359f8",
   "metadata": {},
   "source": [
    "## 3.1 Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1167da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operatietype</th>\n",
       "      <th>Chirurg</th>\n",
       "      <th>Anesthesioloog</th>\n",
       "      <th>Benadering</th>\n",
       "      <th>OK</th>\n",
       "      <th>Casustype</th>\n",
       "      <th>Dagdeel</th>\n",
       "      <th>Leeftijd</th>\n",
       "      <th>Geslacht</th>\n",
       "      <th>AF</th>\n",
       "      <th>...</th>\n",
       "      <th>Hypertensie</th>\n",
       "      <th>Perifeer vaatlijden</th>\n",
       "      <th>CCS</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>Aantal anastomosen</th>\n",
       "      <th>HLM</th>\n",
       "      <th>Geplande operatieduur</th>\n",
       "      <th>Operatieduur</th>\n",
       "      <th>Ziekenhuis ligduur</th>\n",
       "      <th>IC ligduur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amputatie teen + Wondtoilet</td>\n",
       "      <td>6,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK3</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arthroscopische acrominoclaviculaire reconstru...</td>\n",
       "      <td>Ander specialisme</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK 10</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ascendensvervanging</td>\n",
       "      <td>4,00</td>\n",
       "      <td>8,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>TOK1</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Ochtend</td>\n",
       "      <td>78.0</td>\n",
       "      <td>V</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>229.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4,00</td>\n",
       "      <td>2,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ascendensvervanging</td>\n",
       "      <td>7,00</td>\n",
       "      <td>6,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>TOK2</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>66.0</td>\n",
       "      <td>V</td>\n",
       "      <td>J</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>6,00</td>\n",
       "      <td>1,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ascendensvervanging</td>\n",
       "      <td>6,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK2</td>\n",
       "      <td>Spoed</td>\n",
       "      <td>Avond</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Wondtoilet</td>\n",
       "      <td>2,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK1</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>44,00</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>Wondtoilet</td>\n",
       "      <td>4,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK3</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>Wondtoilet</td>\n",
       "      <td>4,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK3</td>\n",
       "      <td>Spoed &lt; 24 uur</td>\n",
       "      <td>Ochtend</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>Wondtoilet</td>\n",
       "      <td>15,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK2</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Middag</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>Wondtoilet</td>\n",
       "      <td>1,00</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOK1</td>\n",
       "      <td>Electief</td>\n",
       "      <td>Ochtend</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Onbekend</td>\n",
       "      <td>Onbekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4086 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Operatietype            Chirurg  \\\n",
       "0                           Amputatie teen + Wondtoilet               6,00   \n",
       "1     Arthroscopische acrominoclaviculaire reconstru...  Ander specialisme   \n",
       "2                                   Ascendensvervanging               4,00   \n",
       "3                                   Ascendensvervanging               7,00   \n",
       "4                                   Ascendensvervanging               6,00   \n",
       "...                                                 ...                ...   \n",
       "4081                                         Wondtoilet               2,00   \n",
       "4082                                         Wondtoilet               4,00   \n",
       "4083                                         Wondtoilet               4,00   \n",
       "4084                                         Wondtoilet              15,00   \n",
       "4085                                         Wondtoilet               1,00   \n",
       "\n",
       "     Anesthesioloog             Benadering     OK       Casustype  Dagdeel  \\\n",
       "0          Onbekend                    NaN   TOK3        Electief   Middag   \n",
       "1          Onbekend                    NaN  OK 10        Electief   Middag   \n",
       "2              8,00  Volledige sternotomie   TOK1        Electief  Ochtend   \n",
       "3              6,00  Volledige sternotomie   TOK2        Electief   Middag   \n",
       "4          Onbekend                    NaN   TOK2           Spoed    Avond   \n",
       "...             ...                    ...    ...             ...      ...   \n",
       "4081       Onbekend                    NaN   TOK1        Electief   Middag   \n",
       "4082       Onbekend                    NaN   TOK3        Electief   Middag   \n",
       "4083       Onbekend                    NaN   TOK3  Spoed < 24 uur  Ochtend   \n",
       "4084       Onbekend                    NaN   TOK2        Electief   Middag   \n",
       "4085       Onbekend                    NaN   TOK1        Electief  Ochtend   \n",
       "\n",
       "      Leeftijd Geslacht   AF  ... Hypertensie Perifeer vaatlijden  CCS NYHA  \\\n",
       "0         51.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "1         50.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "2         78.0        V    N  ...           N                   J  0.0  2.0   \n",
       "3         66.0        V    J  ...           N                   N  2.0  1.0   \n",
       "4         72.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "...        ...      ...  ...  ...         ...                 ...  ...  ...   \n",
       "4081      62.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "4082      62.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "4083      62.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "4084      57.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "4085      64.0      NaN  NaN  ...         NaN                 NaN  NaN  NaN   \n",
       "\n",
       "     Aantal anastomosen  HLM Geplande operatieduur Operatieduur  \\\n",
       "0                   NaN  NaN                  62.0         52.0   \n",
       "1                   NaN  NaN                  85.0         70.0   \n",
       "2                   0.0    N                 229.0        170.0   \n",
       "3                   0.0    N                 140.0        190.0   \n",
       "4                   NaN  NaN                 370.0        480.0   \n",
       "...                 ...  ...                   ...          ...   \n",
       "4081                NaN  NaN                  78.0         65.0   \n",
       "4082                NaN  NaN                  60.0         25.0   \n",
       "4083                NaN  NaN                  46.0         39.0   \n",
       "4084                NaN  NaN                  60.0         46.0   \n",
       "4085                NaN  NaN                  53.0         49.0   \n",
       "\n",
       "     Ziekenhuis ligduur IC ligduur  \n",
       "0              Onbekend   Onbekend  \n",
       "1              Onbekend   Onbekend  \n",
       "2                  4,00       2,00  \n",
       "3                  6,00       1,00  \n",
       "4              Onbekend   Onbekend  \n",
       "...                 ...        ...  \n",
       "4081              44,00       0,00  \n",
       "4082           Onbekend   Onbekend  \n",
       "4083           Onbekend   Onbekend  \n",
       "4084           Onbekend   Onbekend  \n",
       "4085           Onbekend   Onbekend  \n",
       "\n",
       "[4086 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the data from the file: 'surgical_case_durations.csv'. Store it in a dataframe\n",
    "surgicalData = import_df_from_file(FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfa22f",
   "metadata": {},
   "source": [
    "## 3.2 Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8415281",
   "metadata": {},
   "source": [
    "### 3.2.0 - Translate column-names to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c4ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the columns to english\n",
    "surgicalData = surgicalData.rename(columns = TO_ENGLISH_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41984fcf",
   "metadata": {},
   "source": [
    "### 3.2.1 Add new Columns\n",
    "\n",
    "#### Overtime Column\n",
    "Creating the Overtime Column based on the planned- and actual duration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06753937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the overtime column\n",
    "surgicalData = createOvertimeColumn(surgicalData)\n",
    "#Handle the OperationType Column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4182d",
   "metadata": {},
   "source": [
    "#### OperationType\n",
    "The OperationType column has a string with all the operations performed on the subject. The operations, that make up a to over 99% of the total operations are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "942fa266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relevant op types, that cover at least 99% of all operations, are: ['other', 'cabg', 'avr', 'pacemakerdraad tijdelijk', 'mvp', 'mvp shaving', 'wondtoilet', 'tvp', 'mvr']\n"
     ]
    }
   ],
   "source": [
    "OperationTypeEncoder=OPTypeEncoder(n=99)\n",
    "surgicalData=OperationTypeEncoder.fit_transform(surgicalData, 'OperationType')\n",
    "#surgicalData,OPTypeColumnNames = createOperationTypeColumn(surgicalData, 'OperationType')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b63815",
   "metadata": {},
   "source": [
    "### 3.2.2 Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cd8363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the dataset we have some \"onbekend\"-values, that should be NaNs too.\n",
    "surgicalData = replace_with_nan (surgicalData, value = 'Onbekend')\n",
    "\n",
    "#drop columns and rows with too much nan\n",
    "surgicalData, droppedColumns = dropWithTooMuchNan(surgicalData, axis = COLUMN_AXIS)\n",
    "\n",
    "for removeColumnName in droppedColumns:\n",
    "    if removeColumnName in RANGE_COLUMN_NAMES:\n",
    "        RANGE_COLUMN_NAMES.remove(removeColumnName)\n",
    "    if removeColumnName in ORDINAL_COLUMN_NAMES:\n",
    "        ORDINAL_COLUMN_NAMES.remove(removeColumnName)\n",
    "    if removeColumnName in NON_ORDINAL_COLUMN_NAMES:\n",
    "        NON_ORDINAL_COLUMN_NAMES.remove(removeColumnName)\n",
    "    if removeColumnName in NUMERICAL_COLUMN_NAMES:\n",
    "        NUMERICAL_COLUMN_NAMES.remove(removeColumnName)\n",
    "    if removeColumnName in CATEGORICAL_COLUMN_NAMES:\n",
    "        CATEGORICAL_COLUMN_NAMES.remove(removeColumnName)\n",
    "    if removeColumnName in BINARY_COLUMN_NAMES:\n",
    "        BINARY_COLUMN_NAMES.remove(removeColumnName) \n",
    "    if removeColumnName in NORMALIZATION_COLUMN_NAMES:\n",
    "        NORMALIZATION_COLUMN_NAMES.remove(removeColumnName)\n",
    "        \n",
    "surgicalData = dropWithTooMuchNan(surgicalData, axis = ROW_AXIS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd138642",
   "metadata": {},
   "source": [
    "### 3.2.3 Retype the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ba3cf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'BMI', 'ActualDurationTime', 'PlannedDurationTime', 'AmountOfBypasses', 'Euroscore1', 'HospitalDays', 'ICUDays']\n"
     ]
    }
   ],
   "source": [
    "# retype Object columns to categorical columns, if possible\n",
    "surgicalData = convert_df_type(surgicalData, list(surgicalData), 'category')\n",
    "\n",
    "# retype the columns that are not float64 yet\n",
    "surgicalData = convert_df_type(surgicalData, NUMERICAL_COLUMN_NAMES, 'float64')\n",
    "\n",
    "# retype the columns that are not integers yet\n",
    "#surgicalData = convert_df_type(surgicalData, BINARY_COLUMN_NAMES, 'int8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ee504",
   "metadata": {},
   "source": [
    "### 3.2.4 Outlier removal\n",
    "Outlier cutting for the categorical outliers: those outliers will be grouped into \"other\", while the numerical outliers will be removed from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f678c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categoricalOutlier Cutting\n",
    "surgicalData = categorical_outlier_cutting(surgicalData, CATEGORICAL_COLUMN_NAMES, 10)\n",
    "# display(\"after: categorical_outlier_cutting\", surgicalData)\n",
    "\n",
    "# #numericalOutlier Cutting\n",
    "# print(surgicalData.boxplot(column=['ActualDurationTime']))\n",
    "surgicalData = numerical_outlier_cutting(surgicalData, NUMERICAL_COLUMN_NAMES)\n",
    "# print(surgicalData.boxplot(column=['ActualDurationTime']))\n",
    "# display(\"after: numerical_outlier_cutting\", surgicalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e55981c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CCS</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>AmountOfBypasses</th>\n",
       "      <th>PlannedDurationTime</th>\n",
       "      <th>ActualDurationTime</th>\n",
       "      <th>Overtime</th>\n",
       "      <th>Surgeon</th>\n",
       "      <th>Anesthesiologist</th>\n",
       "      <th>Approach</th>\n",
       "      <th>...</th>\n",
       "      <th>ICUDays</th>\n",
       "      <th>OPType_other</th>\n",
       "      <th>OPType_cabg</th>\n",
       "      <th>OPType_avr</th>\n",
       "      <th>OPType_pacemakerdraad tijdelijk</th>\n",
       "      <th>OPType_mvp</th>\n",
       "      <th>OPType_mvp shaving</th>\n",
       "      <th>OPType_wondtoilet</th>\n",
       "      <th>OPType_tvp</th>\n",
       "      <th>OPType_mvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7,00</td>\n",
       "      <td>6,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4,00</td>\n",
       "      <td>10,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3,00</td>\n",
       "      <td>15,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1,00</td>\n",
       "      <td>11,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2,00</td>\n",
       "      <td>5,00</td>\n",
       "      <td>Volledige sternotomie</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  CCS  NYHA  AmountOfBypasses  PlannedDurationTime  ActualDurationTime  \\\n",
       "0  66.0  2.0   1.0               0.0                140.0               190.0   \n",
       "1  71.0  0.0   1.0               0.0                241.0               239.0   \n",
       "2  66.0  0.0   1.0               0.0                240.0               269.0   \n",
       "3  52.0  0.0   1.0               0.0                180.0               305.0   \n",
       "4  80.0  2.0   2.0               0.0                218.0               300.0   \n",
       "\n",
       "   Overtime Surgeon Anesthesiologist               Approach  ... ICUDays  \\\n",
       "0      50.0    7,00             6,00  Volledige sternotomie  ...     1.0   \n",
       "1      -2.0    4,00            10,00  Volledige sternotomie  ...     1.0   \n",
       "2      29.0    3,00            15,00  Volledige sternotomie  ...     0.0   \n",
       "3     125.0    1,00            11,00  Volledige sternotomie  ...     1.0   \n",
       "4      82.0    2,00             5,00  Volledige sternotomie  ...     4.0   \n",
       "\n",
       "  OPType_other OPType_cabg OPType_avr OPType_pacemakerdraad tijdelijk  \\\n",
       "0            J           N          N                               N   \n",
       "1            J           N          N                               N   \n",
       "2            J           N          N                               N   \n",
       "3            J           N          N                               N   \n",
       "4            J           N          J                               N   \n",
       "\n",
       "  OPType_mvp OPType_mvp shaving OPType_wondtoilet OPType_tvp OPType_mvr  \n",
       "0          N                  N                 N          N          N  \n",
       "1          N                  N                 N          N          N  \n",
       "2          N                  N                 N          N          N  \n",
       "3          N                  N                 N          N          N  \n",
       "4          N                  J                 N          N          N  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Needed for the Duration Generator --> Chapter 4\n",
    "priorData=surgicalData[:]\n",
    "surgicalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b25b2a",
   "metadata": {},
   "source": [
    "### 3.2.5 Categorical Data \n",
    "Creating categorical data from ranged numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cfb3138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67-76    694\n",
      "58-66    417\n",
      "77-87    315\n",
      "47-57    244\n",
      "Name: AgeRange, dtype: int64\n",
      "[46, 57, 66, 76, 87]\n",
      "5\n",
      "['47-57', '58-66', '67-76', '77-87']\n",
      "4\n",
      "overweight     819\n",
      "normal         466\n",
      "obese          385\n",
      "underweight      0\n",
      "Name: BMIRange, dtype: int64\n",
      "[17.91, 18.5, 24.9, 29.9, 36.1]\n",
      "5\n",
      "['underweight', 'normal', 'overweight', 'obese']\n",
      "4\n",
      "181-240    665\n",
      "241-280    443\n",
      "281-345    305\n",
      "110-180    192\n",
      "346-398     65\n",
      "Name: ActualDurationTimeRange, dtype: int64\n",
      "[109, 180, 240, 280, 345, 398]\n",
      "6\n",
      "['110-180', '181-240', '241-280', '281-345', '346-398']\n",
      "5\n",
      "181-240    1043\n",
      "241-280     408\n",
      "140-180     119\n",
      "281-330     100\n",
      "Name: PlannedDurationTimeRange, dtype: int64\n",
      "[139, 180, 240, 280, 330]\n",
      "5\n",
      "['140-180', '181-240', '241-280', '281-330']\n",
      "4\n",
      "In_Time                  633\n",
      "Overtime_Small           398\n",
      "Ahead_Of_Time_Medium     312\n",
      "Overtime_Medium          164\n",
      "Ahead_Of_Time_Extreme     94\n",
      "Overtime_Extreme          69\n",
      "Name: OvertimeRange, dtype: int64\n",
      "[-165.0, -70, -25, 25, 70, 120, 215.0]\n",
      "7\n",
      "['Ahead_Of_Time_Extreme', 'Ahead_Of_Time_Medium', 'In_Time', 'Overtime_Small', 'Overtime_Medium', 'Overtime_Extreme']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "surgicalData, column2binNames = to_categorical_range(surgicalData)\n",
    "          \n",
    "for removeColumnName in RANGE_COLUMN_NAMES:\n",
    "    replaceColumnName = removeColumnName+'Range'\n",
    "    if removeColumnName in RANGE_COLUMN_NAMES:\n",
    "        RANGE_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), RANGE_COLUMN_NAMES))\n",
    "    if removeColumnName in ORDINAL_COLUMN_NAMES:\n",
    "        ORDINAL_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), ORDINAL_COLUMN_NAMES))\n",
    "    if removeColumnName in NON_ORDINAL_COLUMN_NAMES:\n",
    "        NON_ORDINAL_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), NON_ORDINAL_COLUMN_NAMES))\n",
    "    if removeColumnName in NUMERICAL_COLUMN_NAMES:\n",
    "        NUMERICAL_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), NUMERICAL_COLUMN_NAMES))\n",
    "    if removeColumnName in CATEGORICAL_COLUMN_NAMES:\n",
    "        CATEGORICAL_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), CATEGORICAL_COLUMN_NAMES))\n",
    "    if removeColumnName in BINARY_COLUMN_NAMES:\n",
    "        BINARY_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), BINARY_COLUMN_NAMES))\n",
    "    if removeColumnName in NORMALIZATION_COLUMN_NAMES:\n",
    "        NORMALIZATION_COLUMN_NAMES = list(map(lambda x: x.replace(removeColumnName, replaceColumnName), NORMALIZATION_COLUMN_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b8334",
   "metadata": {},
   "source": [
    "### 3.2.6 Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919261e",
   "metadata": {},
   "source": [
    "#### Label Encoding\n",
    "This is done for numerical data that is ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e673429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    665\n",
      "2    443\n",
      "3    305\n",
      "0    192\n",
      "4     65\n",
      "Name: ActualDurationTimeRange, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "toBeLE=ORDINAL_COLUMN_NAMES+BINARY_COLUMN_NAMES\n",
    "surgicalData,columnNameToLE = label_encoding(surgicalData, toBeLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c4f1",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n",
    "One hot encoding should be done for the features, that are nominal-scaled.\n",
    "\n",
    "label encoding is done for categorical data, with string names, so that it can be understood by the ml-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5712a81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surgeon\n",
      "OperationRoom\n",
      "Anesthesiologist\n",
      "Approach\n",
      "PartOfDay\n"
     ]
    }
   ],
   "source": [
    "toBeOHE=CATEGORICAL_COLUMN_NAMES\n",
    "\n",
    "surgicalData, codedNames,columnNameToOHE  = one_hot_encoding(toBeOHE, surgicalData)\n",
    "\n",
    "intersectionSFC = set(SURGERY_FEATURES).intersection(CATEGORICAL_COLUMN_NAMES)\n",
    "intersectionPFC = set(PATIENT_FEATURES).intersection(CATEGORICAL_COLUMN_NAMES)\n",
    "for columnName in intersectionSFC:\n",
    "    SURGERY_FEATURES.remove(columnName)\n",
    "for columnName in intersectionPFC:\n",
    "    PATIENT_FEATURES.remove(columnName)\n",
    "\n",
    "#replace the old columns with the encoded ones.\n",
    "CATEGORICAL_COLUMN_NAMES = list(codedNames)+OperationTypeEncoder.relevant_op_types_Names\n",
    "\n",
    "\n",
    "#add the encoded columns to the features.\n",
    "SURGERY_FEATURES += list(codedNames)\n",
    "PATIENT_FEATURES += list(codedNames)\n",
    "\n",
    "#TODO: remove intersection categoricalColumnNames \n",
    "\n",
    "#from surgery features and from patient features.\n",
    "\n",
    "# for codedName in codedNames:\n",
    "#     CATEGORICAL_COLUMN_NAMES.append(list(hotCodedNames[i]))\n",
    "# for columnName in CATEGORICAL_COLUMN_NAMES:\n",
    "#     CATEGORICAL_COLUMN_NAMES.remove(columnName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbb8e8",
   "metadata": {},
   "source": [
    "####  Variance Inflation Factor (VIF)\n",
    "The VIF values indicate how many times larger the variance would become, to create a dataset that would have been uncorrelated. If this VIF value is smaller than 5, that means no significant multicollinearity appears\n",
    "within the dataset.\n",
    "The following code will then produce the output 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9d9485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(multi_col_test(surgicalData))\n",
    "#continue the coding if this is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf785ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c57148db",
   "metadata": {},
   "source": [
    "### 3.2.7 Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6b574",
   "metadata": {},
   "source": [
    "Normalize:\n",
    "- Numerical.\n",
    "- label encoded data.\n",
    "\n",
    "Don't normalize:\n",
    "- Binary Data .\n",
    "- One Hot Encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c0b798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surgicalData = normalize_data(surgicalData)\n",
    "#display(surgicalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2f9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "surgicalData.to_csv(\"PreprocessedSurgicalData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8035f23",
   "metadata": {},
   "source": [
    "# 3.3: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9e72777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AmountOfBypasses</th>\n",
       "      <th>PlannedDurationTime</th>\n",
       "      <th>ActualDurationTime</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AtrialFibrillation</th>\n",
       "      <th>P_ChronicLungDisease</th>\n",
       "      <th>P_extracardialArteriopathy</th>\n",
       "      <th>PreviousHeartSurgery</th>\n",
       "      <th>P_activeEndocarditis</th>\n",
       "      <th>CriticalPre-OP</th>\n",
       "      <th>...</th>\n",
       "      <th>PartOfDay_Middag</th>\n",
       "      <th>PartOfDay_Ochtend</th>\n",
       "      <th>PartOfDay_other</th>\n",
       "      <th>CCS</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>BMIRange</th>\n",
       "      <th>P_PulmonaleHypertension</th>\n",
       "      <th>AgeRange</th>\n",
       "      <th>Euroscore1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.716137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.574794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AmountOfBypasses  PlannedDurationTime  ActualDurationTime  Sex  \\\n",
       "0               0.0                140.0               190.0    1   \n",
       "1               0.0                241.0               239.0    0   \n",
       "2               0.0                240.0               269.0    1   \n",
       "3               0.0                180.0               305.0    1   \n",
       "4               0.0                218.0               300.0    0   \n",
       "\n",
       "   AtrialFibrillation  P_ChronicLungDisease  P_extracardialArteriopathy  \\\n",
       "0                   0                     1                           0   \n",
       "1                   1                     1                           1   \n",
       "2                   1                     1                           1   \n",
       "3                   1                     1                           1   \n",
       "4                   1                     1                           1   \n",
       "\n",
       "   PreviousHeartSurgery  P_activeEndocarditis  CriticalPre-OP  ...  \\\n",
       "0                     1                     1               1  ...   \n",
       "1                     1                     1               1  ...   \n",
       "2                     1                     1               1  ...   \n",
       "3                     1                     1               1  ...   \n",
       "4                     1                     1               1  ...   \n",
       "\n",
       "   PartOfDay_Middag  PartOfDay_Ochtend  PartOfDay_other  CCS      NYHA  \\\n",
       "0               1.0                0.0              0.0  0.5  0.000000   \n",
       "1               0.0                1.0              0.0  0.0  0.000000   \n",
       "2               0.0                1.0              0.0  0.0  0.000000   \n",
       "3               0.0                1.0              0.0  0.0  0.000000   \n",
       "4               1.0                0.0              0.0  0.5  0.333333   \n",
       "\n",
       "   Urgency  BMIRange  P_PulmonaleHypertension  AgeRange  Euroscore1  \n",
       "0      0.0       0.0                      1.0  0.333333    0.716137  \n",
       "1      0.0       1.0                      1.0  0.666667    0.575972  \n",
       "2      0.0       0.5                      1.0  0.333333    0.574794  \n",
       "3      0.0       0.5                      1.0  0.000000    0.373969  \n",
       "4      0.0       0.0                      1.0  1.000000    0.365724  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureData=pd.read_csv(\"PreprocessedSurgicalData.csv\")\n",
    "featureData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08ad5d76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected Features are: ['OPType_other', 'OPType_cabg', 'OPType_avr', 'OPType_pacemakerdraad tijdelijk', 'OPType_mvp', 'OPType_mvp shaving', 'OPType_wondtoilet', 'OPType_tvp', 'OPType_mvr', 'AtrialFibrillation', 'PreviousHeartSurgery', 'P_activeEndocarditis', 'AorticSurgery', 'P_PulmonaleHypertension', 'P_Hypertension', 'CCS', 'NYHA', 'AmountOfBypasses', 'CardiopulmonaryBypassUse']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n",
      "<ipython-input-15-52db3c35653c>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1['const'] = 1 #TODO FIND OUT WHY THE PROGRAMM SPITS OUT WARNINGS HERE AND FIX IT!\n"
     ]
    }
   ],
   "source": [
    "#get data that is our X and data that could be our Y\n",
    "outcomeData = surgicalData[OUTCOME_COLUMN_NAMES]\n",
    "y = outcomeData[PREDICTED_COLUMN]\n",
    "#get the targetNamesString for the classification report\n",
    "targetNamesString = get_target_names_string(y)\n",
    "\n",
    "\n",
    "#find relevant Features based on the surgery\n",
    "featureData = get_feature_data(surgicalData, SURGERY_FEATURES)\n",
    "selectedSurgeryFeaturesData, selectedSurgeryFeatureColumnNames = backward_elimination(featureData, y)\n",
    "#print(selectedSurgeryFeatureColumnNames)\n",
    "#find relevant Features based on the patient\n",
    "featureData = get_feature_data(surgicalData, PATIENT_FEATURES)\n",
    "selectedPatientFeaturesData, selectedPatientFeatureColumnNames = backward_elimination(featureData, y)\n",
    "#print(selectedPatientFeatureColumnNames)\n",
    "\n",
    "selectedFeatureColumnNames=selectedSurgeryFeatureColumnNames+selectedPatientFeatureColumnNames\n",
    "selectedFeatureNames=list(selectedFeatureColumnNames)\n",
    "print(\"The selected Features are:\",selectedFeatureNames)\n",
    "\n",
    "featureData= surgicalData[selectedFeatureNames.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0db0ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureData.to_csv(\"SelectedFeatureData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732fe0d",
   "metadata": {},
   "source": [
    "# Chapter 3.4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28ba4758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPType_other</th>\n",
       "      <th>OPType_cabg</th>\n",
       "      <th>OPType_avr</th>\n",
       "      <th>OPType_pacemakerdraad tijdelijk</th>\n",
       "      <th>OPType_mvp</th>\n",
       "      <th>OPType_mvp shaving</th>\n",
       "      <th>OPType_wondtoilet</th>\n",
       "      <th>OPType_tvp</th>\n",
       "      <th>OPType_mvr</th>\n",
       "      <th>AtrialFibrillation</th>\n",
       "      <th>PreviousHeartSurgery</th>\n",
       "      <th>P_activeEndocarditis</th>\n",
       "      <th>AorticSurgery</th>\n",
       "      <th>P_PulmonaleHypertension</th>\n",
       "      <th>P_Hypertension</th>\n",
       "      <th>CCS</th>\n",
       "      <th>NYHA</th>\n",
       "      <th>AmountOfBypasses</th>\n",
       "      <th>CardiopulmonaryBypassUse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OPType_other  OPType_cabg  OPType_avr  OPType_pacemakerdraad tijdelijk  \\\n",
       "0             0            1           1                                1   \n",
       "1             0            1           1                                1   \n",
       "2             0            1           1                                1   \n",
       "3             0            1           1                                1   \n",
       "4             0            1           0                                1   \n",
       "\n",
       "   OPType_mvp  OPType_mvp shaving  OPType_wondtoilet  OPType_tvp  OPType_mvr  \\\n",
       "0           1                   1                  0           1           1   \n",
       "1           1                   1                  0           1           1   \n",
       "2           1                   1                  0           1           1   \n",
       "3           1                   1                  0           1           1   \n",
       "4           1                   0                  0           1           1   \n",
       "\n",
       "   AtrialFibrillation  PreviousHeartSurgery  P_activeEndocarditis  \\\n",
       "0                   0                     1                     1   \n",
       "1                   1                     1                     1   \n",
       "2                   1                     1                     1   \n",
       "3                   1                     1                     1   \n",
       "4                   1                     1                     1   \n",
       "\n",
       "   AorticSurgery  P_PulmonaleHypertension  P_Hypertension  CCS      NYHA  \\\n",
       "0              0                      1.0               1  0.5  0.000000   \n",
       "1              0                      1.0               0  0.0  0.000000   \n",
       "2              0                      1.0               0  0.0  0.000000   \n",
       "3              0                      1.0               1  0.0  0.000000   \n",
       "4              1                      1.0               1  0.5  0.333333   \n",
       "\n",
       "   AmountOfBypasses  CardiopulmonaryBypassUse  \n",
       "0               0.0                         1  \n",
       "1               0.0                         1  \n",
       "2               0.0                         0  \n",
       "3               0.0                         0  \n",
       "4               0.0                         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureData=pd.read_csv(\"SelectedFeatureData.csv\")\n",
    "featureData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b73344",
   "metadata": {},
   "source": [
    "## 3.4.1 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd22206",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=featureData\n",
    "#As we want to get the performance metrics for the original prediction as well and need the\n",
    "#same split for this, we add 'PlannedDurationTime' here before the train-test-split\n",
    "X = pd.merge(X, surgicalData['PlannedDurationTime'], left_index=True, right_index=True)\n",
    "X = pd.merge(X, surgicalData['PlannedDurationTimeRange'], left_index=True, right_index=True)\n",
    "#split the dataset into training (70%) and testing (30%) sets\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.3,random_state=randomSeed)\n",
    "\n",
    "\n",
    "#Now that the split is done we split the 'Planned Duration Time' from feature split\n",
    "y_test_Original = pd.merge(X_test['PlannedDurationTime'][:],X_test['PlannedDurationTimeRange'][:], left_index=True, right_index=True)\n",
    "X_train.drop(labels=['PlannedDurationTime','PlannedDurationTimeRange'],axis=COLUMN_AXIS, inplace= True)\n",
    "X_test.drop(labels=['PlannedDurationTime','PlannedDurationTimeRange'],axis=COLUMN_AXIS, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32250970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8598f28b",
   "metadata": {},
   "source": [
    "## 3.4.2 Choose a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e450b1",
   "metadata": {},
   "source": [
    "### Dummy-Classifier to get a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac28cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clfs=[DummyClassifier(strategy=\"most_frequent\"),\n",
    "            DummyClassifier(strategy=\"prior\"),\n",
    "            DummyClassifier(strategy=\"stratified\"),\n",
    "            DummyClassifier(strategy=\"uniform\")\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6faaf",
   "metadata": {},
   "source": [
    "### Regression Based Classifier\n",
    "Linear Regression, LogisticRegression, Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27ea12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "reg_clfs=[DummyRegressor(strategy=\"mean\"),\n",
    "          LinearRegression(),\n",
    "          svm.SVC(random_state=randomSeed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee2388",
   "metadata": {},
   "source": [
    "### Tree-Based Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "133b7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_clfs=[tree.DecisionTreeClassifier(max_depth = 1, random_state=randomSeed),\n",
    "           RandomForestClassifier(n_estimators=100,max_depth=5, random_state=randomSeed)\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e94fa1",
   "metadata": {},
   "source": [
    "### Clustering-Based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a1fb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "1# affinity propagation clustering\n",
    "from sklearn.cluster import AffinityPropagation, KMeans, MeanShift, OPTICS, SpectralClustering, MiniBatchKMeans, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cluster_clfs=[\n",
    "    \n",
    "    AffinityPropagation(damping=0.9, random_state=randomSeed),\n",
    "    Birch(threshold=0.01, n_clusters=2),\n",
    "    KMeans(n_clusters=2, random_state=randomSeed),\n",
    "    MiniBatchKMeans(n_clusters=2, random_state=randomSeed),\n",
    "    #MeanShift(),\n",
    "    #OPTICS(eps=0.8, min_samples=10, random_state=randomSeed),\n",
    "    #SpectralClustering(n_clusters=2, random_state=randomSeed),\n",
    "    GaussianMixture(n_components=2, random_state=randomSeed),\n",
    "    KNeighborsClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ab6b6",
   "metadata": {},
   "source": [
    "## 3.4.3 Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54650d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy-classifier\n",
      "\n",
      "DummyClassifier-Strategy:most_frequent\n",
      "MAE error \t 44.950\n",
      "RMSE error \t 57.003\n",
      "\n",
      "DummyClassifier-Strategy:prior\n",
      "MAE error \t 44.950\n",
      "RMSE error \t 57.003\n",
      "\n",
      "DummyClassifier-Strategy:stratified\n",
      "MAE error \t 59.507\n",
      "RMSE error \t 76.560\n",
      "\n",
      "DummyClassifier-Strategy:uniform\n",
      "MAE error \t 77.828\n",
      "RMSE error \t 93.522\n",
      "\n",
      "regression based\n",
      "\n",
      "DummyRegressor\n",
      "MAE error \t 43.616\n",
      "RMSE error \t 54.959\n",
      "\n",
      "LinearRegression\n",
      "MAE error \t 35.918\n",
      "RMSE error \t 45.910\n",
      "\n",
      "SVC\n",
      "MAE error \t 42.513\n",
      "RMSE error \t 54.535\n",
      "\n",
      "tree-based\n",
      "\n",
      "DecisionTreeClassifier\n",
      "MAE error \t 41.186\n",
      "RMSE error \t 51.907\n",
      "\n",
      "RandomForestClassifier\n",
      "MAE error \t 40.062\n",
      "RMSE error \t 50.970\n",
      "\n",
      "clustering based\n",
      "\n",
      "AffinityPropagation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xlbok\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:250: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xlbok\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:528: ConvergenceWarning: This model does not have any cluster centers because affinity propagation did not converge. Labeling every sample as '-1'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xlbok\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE error \t 246.908\n",
      "RMSE error \t 252.903\n",
      "\n",
      "Birch\n",
      "MAE error \t 245.575\n",
      "RMSE error \t 251.615\n",
      "\n",
      "KMeans\n",
      "MAE error \t 245.521\n",
      "RMSE error \t 251.567\n",
      "\n",
      "MiniBatchKMeans\n",
      "MAE error \t 245.521\n",
      "RMSE error \t 251.567\n",
      "\n",
      "GaussianMixture\n",
      "MAE error \t 245.559\n",
      "RMSE error \t 251.595\n",
      "\n",
      "KNeighborsClassifier\n",
      "MAE error \t 61.583\n",
      "RMSE error \t 76.545\n",
      "\n",
      "InverseIndexes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xlbok\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE error \t 45.752\n",
      "RMSE error \t 58.877\n",
      "\n",
      "Original Prediction\n",
      "MAE error \t 45.401\n",
      "RMSE error \t 59.082\n",
      "\n",
      "The classifier with the lowest RMSE ( 45.91019239849399 ) is LinearRegression\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bestClassifier=\"\"\n",
    "\n",
    "if PREDICTED_COLUMN==\"ActualDurationTime\":\n",
    "    report_mode=\"continuos\"\n",
    "    bestEvalScore=-100000\n",
    "    planned_y_test = y_test_Original['PlannedDurationTime']\n",
    "if PREDICTED_COLUMN==\"ActualDurationTimeRange\":\n",
    "    report_mode=\"categorical\"\n",
    "    bestEvalScore=0\n",
    "    planned_y_test = y_test_Original['PlannedDurationTimeRange']\n",
    "\n",
    "    \n",
    "print(\"dummy-classifier\\n\")    \n",
    "strategy=[\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]\n",
    "for c,clf in enumerate(dummy_clfs):\n",
    "    print(clf.__class__.__name__+\"-Strategy:\"+strategy[c])\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted=clf.predict(X_test)\n",
    "    EvalScore=reportPerformance(y_test, predicted,report_mode)\n",
    "    if EvalScore>bestEvalScore:\n",
    "        bestEvalScore=EvalScore\n",
    "        bestClassifier=clf    \n",
    "\n",
    "#only useful if we look at continuos data \n",
    "if PREDICTED_COLUMN==\"ActualDurationTime\":\n",
    "    print(\"regression based\\n\")\n",
    "    for clf in reg_clfs:\n",
    "        print(clf.__class__.__name__)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted=clf.predict(X_test)\n",
    "        EvalScore=reportPerformance(y_test, predicted, report_mode)\n",
    "        if EvalScore>bestEvalScore:\n",
    "            bestEvalScore=EvalScore\n",
    "            bestClassifier=clf\n",
    "\n",
    "print(\"tree-based\\n\")    \n",
    "for clf in tree_clfs:\n",
    "    print(clf.__class__.__name__)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted=clf.predict(X_test)\n",
    "    EvalScore=reportPerformance(y_test, predicted,report_mode)\n",
    "    if EvalScore>bestEvalScore:\n",
    "        bestEvalScore=EvalScore\n",
    "        bestClassifier=clf\n",
    "        \n",
    "print(\"clustering based\\n\")    \n",
    "for clf in cluster_clfs:\n",
    "    print(clf.__class__.__name__)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted=clf.predict(X_test)\n",
    "    EvalScore=reportPerformance(y_test, predicted,report_mode)\n",
    "    if EvalScore>bestEvalScore:\n",
    "        bestEvalScore=EvalScore\n",
    "        bestClassifier=clf\n",
    "\n",
    "print(\"InverseIndexes\")\n",
    "ii = create_ii(X_train.to_numpy())\n",
    "predicted = predict_y_ii(ii, X_test.to_numpy(), y_train.to_numpy())\n",
    "EvalScore=reportPerformance(y_test, predicted,report_mode)\n",
    "if EvalScore>bestEvalScore:\n",
    "    bestEvalScore=EvalScore\n",
    "    bestClassifier=clf\n",
    "    \n",
    "print(\"Original Prediction\")\n",
    "\n",
    "predicted = planned_y_test\n",
    "EvalScore=reportPerformance(y_test, predicted,report_mode)\n",
    "if EvalScore>bestEvalScore:\n",
    "    bestEvalScore=EvalScore\n",
    "    bestClassifier=clf\n",
    "        \n",
    "if report_mode==\"continuos\":\n",
    "    print(\"The classifier with the lowest RMSE (\",str(-bestEvalScore),\") is\", bestClassifier.__class__.__name__)\n",
    "if report_mode==\"categorical\":\n",
    "    print(\"The classifier with the highest acccuracy (\",bestEvalScore,\") is\", bestClassifier.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6e691",
   "metadata": {},
   "source": [
    "# __________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7730e",
   "metadata": {},
   "source": [
    "# Chapter 4: Duration Time Generator\n",
    "- Duration Time Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6d639a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hot encoding\n",
    "hotColumnNames = ['Surgeon', 'OperationRoom', 'Anesthesiologist', 'Approach', \n",
    "                  'PartOfDay']  #TODO hnlich zu CATEGORICAL_COLUMN_NAMES\n",
    "\n",
    "#for label encoding\n",
    "catOrdinalColumnNames = ['CCS', 'NYHA', 'Urgency','BMIRange',\n",
    "                       'LeftVentricleFunction', 'RenalFunction',\n",
    "                       'P_PulmonaleHypertension', 'AgeRange','OvertimeRange','ActualTimeRange']\n",
    "\n",
    "#for binary labeling\n",
    "binaryColumnNames=['Sex', 'AtrialFibrillation', 'P_ChronicLungDisease',\n",
    "                 'P_extracardialArteriopathy', 'PreviousHeartSurgery', \n",
    "                 'P_activeEndocarditis', 'CriticalPre-OP',\n",
    "                 'MycordialInfarctionPreSurgery', 'AorticSurgery',\n",
    "                 'P_PoorMobility', 'P_Diabetis', 'P_Hypercholesterolemia',\n",
    "                 'P_Hypertension', 'P_PeripherialVascularDisease', 'CardiopulmonaryBypassUse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf19e5",
   "metadata": {},
   "source": [
    " ## 4.1 Varibales Needed:\n",
    "- please fill the surgery's Data in\n",
    "\n",
    "Information about the code below:\n",
    "It consists of multiple lists of characteristics. These lists are seperated into three types:\n",
    "\n",
    "- Patient Data: All the information about the patient\n",
    "- Surgery Data: All the information about the surgery\n",
    "- Outcome Data: All the information about the outcome of the surgery. This is asked after the operation, to retrain the model, when enough people have commited the data to us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fc29561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entries that consider data that is clear after the Surgery\n",
    "outcomeData =['ActualDurationTime',\n",
    "              'ICUDays',\n",
    "              'HospitalDays']\n",
    "\n",
    "#Prior_Entries, e.g. the data, that is entered before the operation #only ask for necessary data \n",
    "priorEntries= list(set(SURGERY_FEATURES + PATIENT_FEATURES)&set(priorData.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273ea49",
   "metadata": {},
   "source": [
    "Out of the above we define if we want to use categorical or numerical questioning for our data.\n",
    "\n",
    "- categoryPriorEntries -> Categorical Question\n",
    "- numericalPriorEntries -> numerical Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82b6ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choice category entries, e.g. entries that are prior entries and categorical\n",
    "categoryPriorEntries = list(set(CATEGORICAL_COLUMN_NAMES+catOrdinalColumnNames+binaryColumnNames)&set(priorEntries))\n",
    "\n",
    "#numerical Entries, e.g. entries that are prior entries and numerical\n",
    "numericalPriorEntries = [Entry for Entry in priorEntries if Entry not in categoryPriorEntries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf91b4",
   "metadata": {},
   "source": [
    "Lets see, how many entries we have per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f68a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len prior Entries 35\n",
      "Len cat Entries 33\n",
      "Len num Entries 2\n"
     ]
    }
   ],
   "source": [
    "print('Len prior Entries', len(priorEntries))\n",
    "print('Len cat Entries', len(categoryPriorEntries))\n",
    "print('Len num Entries', len(numericalPriorEntries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde199b",
   "metadata": {},
   "source": [
    "## 4.2 Collect needed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdfbddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a dictionary, that maps from the column-name to the answering options\n",
    "categoryPriorEntries=list(set(priorData.columns)&set(categoryPriorEntries))\n",
    "optionsForEntry={}\n",
    "for c,entry in enumerate(categoryPriorEntries):\n",
    "    data=set(str(i) for i in priorData[entry].unique())\n",
    "    optionsForEntry[entry] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0175db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askUserForCategory(name: str, options: set) ->str:\n",
    "    \"\"\"\n",
    "    asks the user for the correct entry for their patient.\n",
    "    \n",
    "    Input:\n",
    "        name: the name of the entry which is currently in question.\n",
    "        options: is a set with all the options for the entry.\n",
    "        \n",
    "    \n",
    "    returns:\n",
    "        selected: is a string with the choosen option\n",
    "    \"\"\"\n",
    "    #sort the options alphabetically or numerical\n",
    "    options= sorted(options[name])\n",
    "    \n",
    "    print('Please fill in the number that represents your data for',name,':')\n",
    "    \n",
    "    #print all the options with a representative\n",
    "    for index,optionName in enumerate(options):\n",
    "        print(str(index+1) + ')\\t' + optionName)\n",
    "    \n",
    "    #check for valid input\n",
    "    lenListOptions = len(options)\n",
    "    while True:\n",
    "        inputRaw = input(name + ': ')\n",
    "        try:\n",
    "            inputNo = int(inputRaw) - 1\n",
    "            if inputNo > -1 and inputNo < lenListOptions:\n",
    "                selected = list(options)[inputNo]\n",
    "                print('Selected ' +  name + ': ' + selected)\n",
    "                return selected\n",
    "            else:\n",
    "                print('Please select a valid ' + name + ' number')\n",
    "        except ValueError: \n",
    "            print('Please fill in the index of your choice, not the name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032c7bd",
   "metadata": {},
   "source": [
    "The following code will ask the user for the characteristic that is relevant for the entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7eca5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_patient_data():\n",
    "    # create a dict, that saves all the Entries prior to the operation\n",
    "    dictDataEntries= dict.fromkeys(priorEntries) \n",
    "    \n",
    "    # Go through all catgeorical Data points and ask for entry\n",
    "    for i in range(0, len(categoryPriorEntries)):\n",
    "        print()\n",
    "        entry = categoryPriorEntries[i]\n",
    "        newDataPoint = askUserForCategory(entry,optionsForEntry)\n",
    "        dictDataEntries[entry]= [newDataPoint]\n",
    "        #categoryPriorEntries[i][1]=  newDataPoint\n",
    "        \n",
    "    # Go through all numerical Data points and ask for entry\n",
    "    \n",
    "    for i in range(0, len(numericalPriorEntries)):\n",
    "        entry = numericalPriorEntries[i]\n",
    "        print()\n",
    "        newDataPoint =input('Fill in the numerical value for '+ entry + ': ')\n",
    "        dictDataEntries[entry]= [newDataPoint]\n",
    "\n",
    "    newDataDF=pd.DataFrame.from_dict(dictDataEntries)\n",
    "    \n",
    "    return newDataDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newDataDF=get_new_patient_data()\n",
    "newDataDF.to_csv(\"new_data.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce8981",
   "metadata": {},
   "source": [
    "# 5.3 Transform Data According to Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960620",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataDF=pd.read_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0e09b",
   "metadata": {},
   "source": [
    "#### Encode Labels /One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnName in newDataDF.columns:\n",
    "    \n",
    "    if columnName in columnNameToLE.keys():\n",
    "        print(\"LE\",columnName)\n",
    "        newDataDF[columnName] = columnNameToLE[columnName].transform(newDataDF[columnName])\n",
    "    elif columnName in columnNameToOHE.keys():\n",
    "        print(\"OHE\",columnName)\n",
    "        #create OHE\n",
    "        enc=columnNameToOHE[columnName]\n",
    "        data=newDataDF[columnName]\n",
    "        hotCodedArray=enc.transform([list(data)]).toarray()\n",
    "        #Find out columnames\n",
    "        hotCodedcolumns=[]\n",
    "        for category in list(enc.categories_[0]):\n",
    "            hotCodedcolumns+=[columnName+\"_\"+str(category)]\n",
    "        \n",
    "        #create a new df, using the hot coded columns as Column Names\n",
    "        hotCoded = pd.DataFrame(hotCodedArray, columns = hotCodedcolumns)\n",
    "\n",
    "        #remove old data column and add new dataframe\n",
    "        newDataDF.drop(labels=columnName,axis=COLUMN_AXIS, inplace= True)\n",
    "        newDataDF = pd.merge(newDataDF, hotCoded, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44e239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newDataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d365eb",
   "metadata": {},
   "source": [
    "remove features, that have not been selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The selected Features are:\",selectedFeatureNames)\n",
    "\n",
    "featureData= surgicalData[selectedFeatureNames].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a917b",
   "metadata": {},
   "source": [
    "## 5.4 Predict new Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44709e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "patient_data=featureData\n",
    "prediction=bestClassifier.predict(featureData)\n",
    "\n",
    "#check if it has a bin or not\n",
    "if PREDICTED_COLUMN in column2binNames.keys():\n",
    "    print(\"The assumed value for\",PREDICTED_COLUMN,\"in this operation is\", column2binNames[PREDICTED_COLUMN][prediction[0]])\n",
    "else:\n",
    "    print(\"The assumed value for\",PREDICTED_COLUMN,\"in this operation is\", prediction[0])\n",
    "#predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00d24c",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
